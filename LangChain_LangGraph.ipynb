{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMp5e10NlrROYeni7eWfjcT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arvishcdoshi/LangChain-LangGraph/blob/main/LangChain_LangGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WksFzH3Lse6p",
        "outputId": "07a301a2-b18e-46a8-b981-14f43bb6c991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: langchain[groq] in /usr/local/lib/python3.12/dist-packages (1.1.3)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.2 in /usr/local/lib/python3.12/dist-packages (from langchain[groq]) (1.1.3)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain[groq]) (1.0.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain[groq]) (2.12.3)\n",
            "Collecting langchain-groq (from langchain[groq])\n",
            "  Downloading langchain_groq-1.1.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain[groq]) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain[groq]) (0.4.56)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain[groq]) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain[groq]) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain[groq]) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain[groq]) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.2->langchain[groq]) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain[groq]) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain[groq]) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain[groq]) (0.2.15)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain[groq]) (3.6.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[groq]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[groq]) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain[groq]) (0.4.2)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq->langchain[groq])\n",
            "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq->langchain[groq]) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq->langchain[groq]) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq->langchain[groq]) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq->langchain[groq]) (1.3.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.2->langchain[groq]) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain[groq]) (1.12.0)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph<1.1.0,>=1.0.2->langchain[groq]) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain[groq]) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain[groq]) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain[groq]) (0.25.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq->langchain[groq]) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq->langchain[groq]) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq->langchain[groq]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq->langchain[groq]) (0.16.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain[groq]) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.2->langchain[groq]) (2.5.0)\n",
            "Downloading langchain_groq-1.1.0-py3-none-any.whl (19 kB)\n",
            "Downloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.37.1 langchain-groq-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-dotenv langchain[groq]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get('groqApiKey')"
      ],
      "metadata": {
        "id": "ntueq63as-Ew"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "model = init_chat_model(\"qwen/qwen3-32b\", model_provider=\"groq\")"
      ],
      "metadata": {
        "id": "DViJnTittIBN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.invoke(\"Explain me about neural networks\")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "-qcIKc5qtLsH",
        "outputId": "2108c8ba-c1dc-47a1-8fb4-43a6764d28a2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<think>\\nOkay, so I need to explain neural networks. Let me start by recalling what I know. Neural networks are inspired by the human brain, right? They consist of layers of nodes, called neurons. Each neuron takes inputs, processes them, and produces an output. \\n\\nFirst, maybe I should break down the basic structure. There's the input layer, which is where the data starts. Then there are hidden layers, which process the data in steps. Finally, there's the output layer, which gives the result. Each neuron in a layer is connected to neurons in the next layer, and these connections have weights‚Äîlike adjustable parameters that determine the strength of the connection. \\n\\nWait, how does the processing work? Each neuron sums up the weighted inputs and applies an activation function. Activation functions introduce non-linearity, allowing the network to model complex patterns. Common ones include ReLU, sigmoid, and tanh. Oh, right, without activation functions, the network would just be a linear model. \\n\\nTraining a neural network involves adjusting the weights and biases. That's done through a process called backpropagation. But how does backpropagation work? It uses gradient descent to minimize a loss function, which measures the difference between the predicted and actual outputs. The gradients are calculated using the chain rule to update each weight in the network. \\n\\nOptimization algorithms like Adam or SGD tune the learning rate and help the model converge faster. Also, there's the concept of epochs‚Äîeach epoch is a full pass through the training dataset. But too many epochs can lead to overfitting, so techniques like cross-validation or early stopping are used.\\n\\nI should mention different types of neural networks. For example, CNNs for images, RNNs for sequences, and transformers for NLP tasks. Each has a specific architecture suited to their data type. Maybe I should explain a simple example, like a perceptron, which is a single-layer neural network, but most real applications use deeper networks.\\n\\nAlso, important concepts like overfitting, underfitting, and regularization techniques such as dropout or weight decay. Maybe talk about the components again: weights, biases, activation functions, loss functions. Maybe mention some applications to make it concrete‚Äîlike image recognition, language translation, game playing (AlphaGo), etc.\\n\\nWait, did I miss anything? Oh, the process of forward propagation and backpropagation. Let me outline the steps: initialize weights, forward pass to compute output, calculate loss, backpropagate errors to compute gradients, update weights. Maybe include a simple mathematical example to illustrate, like using a simple network with one input, one hidden layer, and one output. But maybe that's too detailed for a basic explanation.\\n\\nI should also touch on the challenges, like the need for large datasets, computational resources, and the risk of overfitting. Maybe mention deep learning as a subset of machine learning that uses neural networks with many layers. Also, the importance of data preprocessing and feature engineering in preparing input data for the network.\\n\\nPutting it all together, the explanation should start with the basic structure, how neurons process information, training methods, different types of networks, and their applications. Keep it in simple terms without too much jargon, but still accurate. Make sure to clarify common misunderstandings, like how neural networks don't mimic the brain exactly but are inspired by it.\\n</think>\\n\\nNeural networks are computational models inspired by the structure and function of the human brain. They are a cornerstone of **deep learning**, a subset of machine learning that enables systems to learn complex patterns from data. Here's a structured breakdown of their key concepts:\\n\\n---\\n\\n### **1. Basic Structure of a Neural Network**\\n- **Layers**:\\n  - **Input Layer**: Receives raw data (e.g., pixel values of an image).\\n  - **Hidden Layers**: Intermediate layers that process data hierarchically. Each neuron performs computations.\\n  - **Output Layer**: Produces the final result (e.g., class probabilities in classification).\\n\\n- **Neurons (Nodes)**:\\n  - Each neuron processes weighted inputs and generates an output.\\n  - **Weights**: Adjustable parameters that determine the influence of each input.\\n  - **Bias**: An offset added to the weighted sum, allowing flexibility in the model.\\n\\n---\\n\\n### **2. How Neurons Work**\\n- **Processing**:\\n  1. **Weighted Sum**: Each input $ x_i $ is multiplied by its corresponding weight $ w_i $, and all are summed:\\n     $$\\n     z = \\\\sum_{i} (w_i \\\\cdot x_i) + b\\n     $$\\n  2. **Activation Function**: Introduces non-linearity to capture complex patterns. Common functions include:\\n     - **ReLU**: $ f(z) = \\\\max(0, z) $\\n     - **Sigmoid**: $ f(z) = \\\\frac{1}{1 + e^{-z}} $\\n     - **Tanh**: $ f(z) = \\\\tanh(z) $\\n\\n---\\n\\n### **3. Training a Neural Network**\\n- **Objective**: Adjust weights and biases to minimize the **loss function** (e.g., mean squared error for regression, cross-entropy for classification).\\n- **Key Steps**:\\n  1. **Forward Propagation**: Compute the output layer by layer.\\n  2. **Loss Calculation**: Compare predicted output to the true label using a loss function.\\n  3. **Backpropagation**: \\n     - Calculate gradients of the loss with respect to each parameter using the **chain rule**.\\n     - Update weights via **gradient descent**:\\n       $$\\n       w_{\\\\text{new}} = w_{\\\\text{old}} - \\\\eta \\\\cdot \\\\frac{\\\\partial \\\\text{Loss}}{\\\\partial w}\\n       $$\\n       (where $ \\\\eta $ is the learning rate).\\n  4. **Optimization**: Algorithms like **Adam** or **Stochastic Gradient Descent (SGD)** control learning efficiency.\\n\\n---\\n\\n### **4. Types of Neural Networks**\\n- **Perceptron**: Single-layer network for linear problems.\\n- **Deep Neural Networks (DNNs)**: Multiple hidden layers for complex tasks.\\n- **Convolutional Neural Networks (CNNs)**: Specialized for images using **convolutional layers** to detect spatial patterns.\\n- **Recurrent Neural Networks (RNNs)**: Handle sequential data (e.g., text, time series) via **recurrent connections**.\\n- **Transformers**: Use **self-attention mechanisms** for tasks like language translation (e.g., BERT, GPT).\\n\\n---\\n\\n### **5. Challenges and Solutions**\\n- **Overfitting**: Model performs well on training data but poorly on unseen data.\\n  - **Solutions**: Regularization (dropout, weight decay), cross-validation, data augmentation.\\n- **Underfitting**: Model is too simple to capture patterns.\\n  - **Solutions**: Increase network depth/complexity, more training data.\\n- **Computational Cost**: Training deep networks requires significant resources (GPUs/TPUs).\\n- **Data Requirements**: Large, labeled datasets are often needed.\\n\\n---\\n\\n### **6. Applications**\\n- **Computer Vision**: Image classification (e.g., ResNet), object detection.\\n- **Natural Language Processing (NLP)**: Language translation (e.g., Google Translate), chatbots.\\n- **Reinforcement Learning**: Game playing (e.g., AlphaGo), robotics.\\n- **Healthcare**: Medical imaging analysis, drug discovery.\\n\\n---\\n\\n### **7. Example Workflow**\\n1. **Input**: An image (e.g., 28x28 pixels for MNIST digits).\\n2. **Processing**:\\n   - Pass through convolutional layers to detect edges/textures.\\n   - Flatten into a vector.\\n   - Pass through dense layers for classification.\\n3. **Output**: Probability distribution over digit classes (0‚Äì9).\\n\\n---\\n\\n### **Key Takeaways**\\n- Neural networks are universal function approximators, capable of modeling highly non-linear relationships.\\n- Success hinges on proper architecture design, hyperparameter tuning, and sufficient data.\\n- While inspired by biology, they are simplified abstractions and differ significantly from biological neural systems.\\n\\nBy iteratively refining weights through training, neural networks learn to generalize from examples, making them powerful tools for a wide range of applications.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.invoke(\"Who is the prime minister of India\")\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "ZISPpInLGt3z",
        "outputId": "ad40604e-aa0f-4b5b-f181-ccb44ed58488"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<think>\\nOkay, the user is asking for the current Prime Minister of India. Let me recall the information I have. As of my last update in October 2023, the Prime Minister of India is Narendra Modi. He has been serving in this role since May 2014, and he's from the Bharatiya Janata Party (BJP). I should confirm if there have been any changes since then. I don't think there have been any recent changes, so he's still the current PM.\\n\\nI need to make sure I present the answer clearly. The user might be looking for a straightforward answer without any extra details, but maybe they also want some context. I should mention his party, the years in office, and perhaps his significance. Also, considering the user might not know the political structure, it's good to add that he was re-elected in 2019 and 2024. Wait, the 2024 election hasn't happened yet as of October 2023. The next general election is tentatively scheduled for 2024, but he's still the current PM until then. So I should avoid mentioning 2024 unless I'm certain. Let me check the exact dates. The term of a Prime Minister is five years, so his current term started in 2019 after the 2019 election. The next election would be in 2024, but since it hasn't occurred yet, he remains in office. \\n\\nI should also verify if there's any interim PM or acting PM scenario. I don't recall any such situation. The BJP has retained power in the state elections that have taken place since 2023, so it's likely they'll win the 2024 election, but that's speculative. The user's question is about the current PM, so sticking to the facts without predictions is safer. \\n\\nAdditionally, maybe the user wants to know a bit more about him. Including his role as the head of government and the leader of the BJP would be helpful. Also, noting his re-election in 2019. Let me structure the answer: name, party, start of term, re-election, and role. Keep it concise but informative. Avoid any political bias, just state the facts. Double-check the dates to ensure accuracy. Yes, he took office in May 2014, re-elected in 2019. No other leaders have taken over in between. That should cover it.\\n</think>\\n\\nAs of October 2023, the **Prime Minister of India** is **Narendra Modi**. He has served as Prime Minister since **May 26, 2014**, and was re-elected in **2019** for a second five-year term. A leader of the **Bharatiya Janata Party (BJP)**, Modi is one of the most prominent political figures in India and has been instrumental in shaping the country's policies and governance. The next general election is tentatively scheduled for **2024**, after which his current term will conclude. \\n\\nLet me know if you'd like additional details!\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "\n",
        "model.invoke(\"Hello\")\n",
        "\n",
        "model.invoke([{\"role\": \"user\", \"content\": \"Hello\"}])\n",
        "\n",
        "model.invoke([HumanMessage(\"Hello\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHkq_JtmtpZa",
        "outputId": "eddd4777-5ce1-4e9a-c167-efc0bc9277d3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='<think>\\nOkay, the user just said \"Hello\". That\\'s a standard greeting. I should respond in a friendly and welcoming manner. Let me make sure to acknowledge their greeting and offer assistance. Maybe something like, \"Hello! How can I assist you today?\" That should cover it. I need to keep it simple and open-ended to encourage them to ask their question or share what they need help with.\\n</think>\\n\\nHello! How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 94, 'prompt_tokens': 9, 'total_tokens': 103, 'completion_time': 0.159068562, 'completion_tokens_details': None, 'prompt_time': 0.000529421, 'prompt_tokens_details': None, 'queue_time': 0.021526437, 'total_time': 0.159597983}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_d58dbe76cd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b13b6-a243-7f01-b7f2-b197dafdddcb-0', usage_metadata={'input_tokens': 9, 'output_tokens': 94, 'total_tokens': 103})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(\"Suggest me name of a place in one word to travel in India\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGjuCTluttVg",
        "outputId": "a75be7a6-acd4-407a-83c6-6c0149033bef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='<think>\\nOkay, the user wants a one-word name of a place in India to travel. Let me start by brainstorming some popular locations. There\\'s Kerala, known for its backwaters and beaches. Then there\\'s Rajasthan, famous for forts and deserts. Maybe Goa for its beaches and nightlife. But wait, the user might prefer a more unique or less obvious suggestion.\\n\\nHmm, I should consider different regions. The north has places like Ladakh, which is stunning with mountains and lakes. In the south, there\\'s Tamil Nadu with places like Thanjavur. But maybe a single word that\\'s a city or town. Udaipur comes to mind, the \"City of Lakes.\" Or Jaipur, the Pink City. \\n\\nWait, the user might want a word that\\'s a bit more poetic or has a specific appeal. Like Rishikesh for spiritual seekers, or Leh in Ladakh. But I need to make sure it\\'s a single word. Let me verify. Rishikesh is two words. Leh is one. How about Haridwar? That\\'s one word. Or maybe a temple town like Varanasi? But Varanasi is a single word. \\n\\nWait, the user might be looking for a place that\\'s not too common. Places like Hampi, which is a UNESCO site with ruins. That\\'s one word. Or maybe Khajuraho for temples. Let me check if those are one word. Yes, both are single words. \\n\\nAlternatively, a hill station like Darjeeling. That\\'s one word. Or Manali? No, Manali is one word. Wait, Manali is a good option. But maybe the user prefers a place that\\'s more off the beaten path. \\n\\nWait, the user might not have specific preferences, so I should pick a place that\\'s well-known but still has a unique charm. Kerala is a state, but maybe a city within it. Cochin? That\\'s one word. Or maybe a city like Udaipur. \\n\\nWait, the user might want a place that\\'s a single word and perhaps has a nice ring to it. Let me think of some more. Jaisalmer in Rajasthan is a single word. Or maybe Hampi. \\n\\nI think I need to choose the most iconic one that\\'s a single word. Leh in Ladakh is a good choice. It\\'s a popular travel destination with breathtaking landscapes. Alternatively, Rishikesh is a single word if we consider it as one. Wait, Rishikesh is two words? No, it\\'s one word. Rishikesh is a single word. \\n\\nBut maybe the user wants a place that\\'s less known. Hmm. Let me check the spelling again. Leh is one word. Leh, Ladakh. Yes. So Leh is a good option. Alternatively, Darjeeling. Both are single words. \\n\\nI think I\\'ll go with Leh because it\\'s a unique destination with a lot to offer and is a single word. But maybe the user wants a different type of place. Let me confirm. If they\\'re looking for beaches, Goa. For spiritual, Varanasi. For hill stations, Darjeeling. Since the user didn\\'t specify, perhaps a balance between popular and unique. \\n\\nAnother option is Hampi, which is a UNESCO World Heritage Site. It\\'s one word and has historical significance. Maybe that\\'s a good choice. Let me verify. Yes, Hampi is a single word. \\n\\nAlternatively, the city of Jaipur is a single word and a major tourist spot. But maybe the user wants something more scenic. \\n\\nI think I\\'ll suggest Hampi as the answer. It\\'s a single word, a unique destination with ancient ruins, and it\\'s not as crowded as some other places. That should work.\\n</think>\\n\\n**Hampi**  \\n\\nNestled in Karnataka, Hampi is a UNESCO World Heritage Site renowned for its ancient ruins, serene landscapes, and rich historical significance. It offers a unique blend of adventure, culture, and tranquility, making it a captivating one-word travel destination in India.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 839, 'prompt_tokens': 22, 'total_tokens': 861, 'completion_time': 1.932641582, 'completion_tokens_details': None, 'prompt_time': 0.000696839, 'prompt_tokens_details': None, 'queue_time': 0.024899279, 'total_time': 1.933338421}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_efa9879028', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b13b6-dcf9-7d92-9b96-aee948996efb-0', usage_metadata={'input_tokens': 22, 'output_tokens': 839, 'total_tokens': 861})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "travel_template = \"Suggest me name of a place in one word to travel in {country}\"\n",
        "prompt_template = ChatPromptTemplate.from_messages([(\"system\", travel_template), (\"user\", \"{country}\")])"
      ],
      "metadata": {
        "id": "YlRoZFCctxMH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = prompt_template.invoke({\"country\": \"India\"})"
      ],
      "metadata": {
        "id": "5osmyLcet0D1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-dlEpwTt3Gf",
        "outputId": "66ca9036-06e8-4f26-b102-b73e2d26f0be"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='<think>\\nOkay, the user wants a one-word name of a place to travel in India. Let me think about popular destinations. There are so many options, but I need to narrow it down to one. Let\\'s see... Heritage sites, beaches, hill stations, spiritual places?\\n\\nFirst, considering heritage, places like Jaipur (Pink City) or Agra (for the Taj Mahal). But maybe too obvious. Spiritual places like Varanasi or Amritsar. Natural beauty could be places like Darjeeling or Kerala. Beaches like Goa or Kerala again.\\n\\nWait, the user might appreciate a place that\\'s unique and has multiple attractions. Maybe a city known for more than one thing. Leh in Ladakh is beautiful but maybe a bit remote. Udaipur is a popular tourist spot with lakes and palaces. Rishikesh is a spiritual hub and has adventure activities.\\n\\nAlternatively, places like Kerala are a state, but the user asked for a place. Maybe a specific city or town. Let me think of one-word names. Jaipur, Udaipur, Varanasi, Goa, Amritsar, Darjeeling, Shimla, Manali, Rishikesh...\\n\\nWait, maybe \"Kerala\" is a state but sometimes referred to as a single entity. But the user might want a city. Alternatively, \"Hampi\" for historical ruins. Or \"Ajanta\" for caves. Hmm.\\n\\nAnother angle: UNESCO sites. Ajanta or Ellora Caves. But maybe not as well-known. Or \"Rajasthan\" but that\\'s a state. Let me think again. The user might be looking for a famous city that\\'s easy to remember. Jaipur is a good candidate. It\\'s a city in Rajasthan, known for its forts, palaces, and the pink color. Plus, it\\'s one word. Or \"Udaipur\" which is another city in Rajasthan with lakes. But maybe Jaipur is more iconic.\\n\\nAlternatively, \"Varanasi\" for spiritual seekers. It\\'s a one-word name and a major destination. Or \"Goa\" for beaches and nightlife. But maybe the user wants something more off the beaten path. \"Shimla\" is a hill station. \"Darjeeling\" for tea plantations. \\n\\nWait, the user might prefer a place that\\'s both a city and a destination with multiple attractions. Jaipur checks that off. It\\'s a single word, well-known, and has a variety of things to do. I think Jaipur is a solid choice. Let me confirm if there\\'s any other place that\\'s more unique or iconic. Maybe \"Hampi\" for the ruins, but it\\'s less known. \"Kerala\" is a state, maybe not a single place. \\n\\nI think Jaipur is the best one-word recommendation here. It\\'s concise, memorable, and offers a rich cultural experience.\\n</think>\\n\\n**Jaipur** ‚Äì The \"Pink City\" of Rajasthan, known for its majestic forts, palaces, and vibrant cultural heritage.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 623, 'prompt_tokens': 28, 'total_tokens': 651, 'completion_time': 1.8361540079999998, 'completion_tokens_details': None, 'prompt_time': 0.002307148, 'prompt_tokens_details': None, 'queue_time': 0.02414793, 'total_time': 1.8384611560000002}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_d58dbe76cd', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b13b7-79e8-7b40-a202-d1e160e34fae-0', usage_metadata={'input_tokens': 28, 'output_tokens': 623, 'total_tokens': 651})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = ChatPromptTemplate.from_template(\"Suggest me name of a place in one word to travel in {country} in month {month}\")\n",
        "prompt = prompt_template.invoke({\"country\": \"India\", \"month\": \"December\"})\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8pFxCn5t8SA",
        "outputId": "b5c3b9fa-5df8-4d37-c07c-47ed0aaf5335"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "messages=[HumanMessage(content='Suggest me name of a place in one word to travel in India in month December', additional_kwargs={}, response_metadata={})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.invoke(prompt)\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "Ve0kq8WLuAUH",
        "outputId": "87411335-7a67-49ec-9cfd-9f9096d7bdf3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<think>\\nOkay, the user wants a single-word name of a place in India to visit in December. Let me think about the best options.\\n\\nDecember in India is winter, so it\\'s cold in the north and pleasant in the south. Popular northern destinations are places like Shimla, Manali, or Gulmarg for skiing. But the user asked for one word. Maybe \"Shimla\" is a good choice. It\\'s a hill station, famous, and a single word. \\n\\nAlternatively, \"Udaipur\" is in Rajasthan and has a winter season, but it might be a bit hot compared to hill stations. \"Jaipur\" is another option but not as winter-specific. In the south, \"Munnar\" in Kerala is a hill station, but December is the end of the monsoon there, so maybe not ideal. \"Hampi\" is a historical site, but again, it\\'s warm in December there. \\n\\nWait, \"Shimla\" is a hill station, part of Himachal Pradesh, and December is perfect for it with snowfall sometimes. It\\'s a single word, well-known, and fits the season. Another thought: \"Leh\" is in Ladakh, which is colder, but December might be too harsh. \"Manali\" is another option but again, might be more than one word? No, \"Manali\" is one word. But \"Shimla\" is more established as a tourist spot in December. \\n\\nI think \"Shimla\" is the best fit. It\\'s concise, fits the season, and is a popular destination. Let me confirm if there are any other single-word options. \"Nainital\" is another hill station but maybe less known. \"Gulmarg\" is a good one for skiing but might not be a single word. Hmm, \"Gulmarg\" is single word. But Shimla is more accessible and a classic choice. Yeah, I\\'ll go with Shimla.\\n</think>\\n\\n**Shimla**  \\nThis hill station in Himachal Pradesh is a popular winter destination in December, offering snowfall, serene landscapes, and a charming colonial vibe.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chaining"
      ],
      "metadata": {
        "id": "g_Wd9l_muhy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "travel_destination_chain = prompt_template | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "cjK02BS5uifJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "travel_destination_chain.invoke({\"country\": \"India\", \"month\": \"December\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "ckUtfi4jundX",
        "outputId": "008dbf5a-1143-4488-847c-52dbbe31897b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<think>\\nOkay, the user wants a single-word place in India to travel in December. Let me start by thinking about the best times to visit different regions. December is winter in North India, so places like Rajasthan might be great for their festivals and pleasant weather. Jaipur comes to mind with its festivals and forts.\\n\\nThen there\\'s the South, like Kerala, which has the backwaters and maybe the Nehru Trophy Boat Race in February, but December is still good. But the user wants a one-word name. Kerala is a state, but maybe a specific town? Cochin? But maybe the state name is better.\\n\\nHimachal Pradesh has snow, but December is the start of winter. Manali? But again, the state name might be better. Then there\\'s Goa, which has a nice beach climate in December. But Goa is a state, but the user might be okay with that. Wait, the user said \"one word,\" so maybe a city? Like Udaipur? It\\'s in Rajasthan, has festivals in December. Or maybe Kerala is a good option because of the backwaters and weather.\\n\\nWait, also, the Western Ghats have good weather in December. Places like Ooty in Tamil Nadu? But again, the state might be better. Let me check if there are any festivals in December. Rajasthan has the Jaipur Literature Festival in January, but maybe other events. The Desert Festival in Jaisalmer is in February. Hmm. So maybe Rajasthan is a good choice for its forts and culture in December.\\n\\nAlternatively, the hill stations like Shimla or Darjeeling. But December is a bit early for snow in Manali. Maybe Kerala is better because of the climate and activities like houseboat rides. Goa is popular for beaches and New Year\\'s Eve. But the user wants a place name, not a state. Wait, the user said \"one word,\" so maybe a city. Let me think: Jaipur, Udaipur, Kerala, Goa, Cochin, Darjeeling, Shimla. Which one is most recommended? Kerala is a state, but maybe the user is okay with that. Alternatively, maybe a specific city in Kerala like Thiruvananthapuram? But that\\'s less known. Hmm.\\n\\nWait, the user might prefer a city or a well-known place. So maybe Goa, Kerala, or Rajasthan. Let me check which of these is typically recommended in December. Goa is very popular in December for New Year\\'s Eve. Rajasthan\\'s weather is pleasant, and festivals like the Jaipur International Film Festival in December. Also, the Udaipur festival of lights in February? Wait, not sure. Maybe the user is looking for a place that\\'s iconic for December. So Goa is a solid choice. Alternatively, Kerala\\'s backwaters are a year-round destination. Hmm. I think Goa is a strong contender because of the New Year\\'s celebrations. But if the user wants a place with cultural and historical significance, Rajasthan\\'s cities like Jaipur or Jodhpur. Alternatively, maybe a hill station like Shimla or Mussoorie. But December is a bit early for snow. Let me confirm the best places for December in India. A quick mental check: December is winter, so North India\\'s weather is good, South India is warm and pleasant. So places like Rajasthan, Kerala, Goa. The user wants a one-word name. So I\\'ll go with Kerala, Goa, Rajasthan, or maybe a city like Udaipur. But the user might prefer a state. So between Kerala and Goa. I think Kerala is a good answer because of the backwaters and pleasant weather, plus it\\'s a single word. Alternatively, Goa for the beaches and New Year\\'s. Hmm. I\\'ll go with Kerala as the answer, but maybe also consider Goa. Wait, the user hasn\\'t specified between state or city, but the example answer given in the previous interaction was Kerala. Alternatively, maybe the user wants a city. Let me check the example again. The user\\'s previous question was about a one-word place in December, and the assistant suggested Kerala. So maybe the user expects a state name. So I\\'ll go with Kerala as the answer.\\n</think>\\n\\n**Kerala** is an excellent one-word choice for travel in India during December. Known for its tropical climate, serene backwaters, and cultural festivals like the Nehru Trophy Boat Race (February), Kerala offers a pleasant escape with its lush landscapes, Ayurvedic retreats, and vibrant traditions. December also marks the start of the winter season, making it ideal for exploring the region\\'s natural beauty without the monsoon rains.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "travel_itinerary_prompt = ChatPromptTemplate.from_template(\"Give me 3 days itinerary for the place {destination}\")"
      ],
      "metadata": {
        "id": "VVIIVhJpusuf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "composed_chain = {\"destination\" : travel_destination_chain} | travel_itinerary_prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "TWB2toDbuvCg"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "composed_chain.invoke({\"country\": \"India\", \"month\": \"June\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "QBcHZQEuuxbH",
        "outputId": "a230db34-5d14-4480-8b88-7c3e501ddb28"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<think>\\nOkay, the user asked for a 3-day itinerary for Shimla. Let me start by recalling the key attractions there. Shimla is a hill station in Himachal Pradesh, known for its colonial architecture, cool climate, and scenic views. First, I should outline the main spots: places like the Ridge, Mall Road, Jakhoo Temple, and Kufri. Also, nearby attractions like Kala Patthar or the British-era architecture.\\n\\nFor Day 1, I'll focus on the central areas. Morning at Ridge and Sungei Mani, check. Then explore Mall Road in the afternoon for shopping and food. Evening could be a view point like the Clock Tower or the Christ Church. Maybe include a visit to the Summerhill Club for the sunset. Need to make sure the timing is realistic, like leaving enough time between locations.\\n\\nDay 2 should include a day trip. Kufri is about 18 km away, so an early start. Visit the Kufri Hill, Toy Train, and maybe a cable car. Afternoon could head to the Tibetan Market or the Nehru Institute of Mountaineering. Evening back in Shimla, maybe relax at the Lakkar Bazaar or the Gaiety Theatre.\\n\\nDay 3 options: Jakhoo Temple in the morning, which is a bit of a hike or drive. Then check out the Indian Institute of Advanced Studies. Afternoon could be Kala Patthar for panoramic views. Evening wrap up with a walk around Scandal Point or a local eatery. Need to check distances and travel times to ensure it's feasible.\\n\\nI should also mention local cuisine, like siddu and churmur, and maybe suggest some cozy cafes. Transportation tips: taxis or local buses. Also, mention carrying jackets as it can get chilly. Let me structure each day with a mix of activities, ensuring a balance between sightseeing, relaxation, and local experiences. Avoid overcrowded places if possible, but Shimla is usually manageable. Check for any seasonal closures or road conditions, but June is generally good. Make sure the itinerary isn't too packed, allowing for flexibility. Alright, let's put it all together.\\n</think>\\n\\n**3-Day Itinerary for Shimla, India**  \\n*Escape to the cool, colonial charm of Shimla, a hill station in Himachal Pradesh, perfect for June's summer retreat.*  \\n\\n---\\n\\n**Day 1: Colonial Elegance & Scenic Views**  \\n- **Morning**: Start at **The Ridge** (Shimla's central hub) and visit **Sungei Mani** (Governor's Summerhouse).  \\n- **Afternoon**: Explore **Mall Road**, Shimla‚Äôs bustling promenade, lined with colonial buildings, caf√©s, and shops. Visit **Christ Church** (one of India‚Äôs oldest Gothic churches).  \\n- **Evening**: Stroll to **Clock Tower** and enjoy a cup of tea at **Summerhill Club** while soaking in mountain views.  \\n\\n**Local Tip**: Try *siddu* (steamed flatbread) and *churmur* (papad salad) at local dhabas.  \\n\\n---\\n\\n**Day 2: Adventure to Kufri**  \\n- **Morning**: Take a 40-minute drive to **Kufri**, a nearby hilltop village. Visit **Kufri Hill** for panoramic views and ride the **Toy Train** (part of the UNESCO World Heritage Mountain Railways).  \\n- **Afternoon**: Explore the **Tibetan Market** (handmade crafts) or **Nehru Institute of Mountaineering** (if open).  \\n- **Evening**: Return to Shimla and unwind at **Gaiety Theatre** (colonial-era performances) or relax at **Lakkar Bazaar** (wooden handicrafts).  \\n\\n**Transport Tip**: Hire a taxi or book a local bus for the Kufri trip.  \\n\\n---\\n\\n**Day 3: Spirituality & Panoramic Vistas**  \\n- **Morning**: Drive to **Jakhoo Temple**, a revered Hindu shrine with a trek through pine forests. Capture views of **Gaiety Theatre** from the top.  \\n- **Afternoon**: Visit **Indian Institute of Advanced Studies** (a serene campus) and **Kala Patthar**, a viewpoint offering 360¬∞ vistas of the Himalayas.  \\n- **Evening**: Wind down with a walk at **Scandal Point** or savor a final meal at **The Great Peaks Restaurant**.  \\n\\n**Clothing Tip**: Carry a light jacket‚ÄîShimla‚Äôs evenings can turn chilly!  \\n\\n---\\n\\n**Why Shimla?**  \\n- **Weather**: June brings pleasant 15‚Äì25¬∞C temps, ideal for exploring.  \\n- **Highlights**: Blend of colonial history, nature, and adventure.  \\n- **Bonus**: Safe, well-connected, and less crowded than other hill stations.  \\n\\nEnjoy your retreat! üåÑ\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangGraph"
      ],
      "metadata": {
        "id": "EnlY8ojfu48I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2auoz6-tu4lu",
        "outputId": "413643b6-faed-4593-b495-571ccd910019"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.4)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.1.3)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.15)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langgraph) (2.12.3)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.4.56)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core>=0.1->langgraph) (0.12.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.5)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph) (2.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph"
      ],
      "metadata": {
        "id": "dUU_ERszu91C"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2VPfnc9Hvce2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict\n",
        "\n",
        "# Define the state schema for your graph\n",
        "class GraphState(TypedDict):\n",
        "  x: int\n",
        "  y: int\n",
        "  func1_output: int\n",
        "  func2_output: int\n",
        "\n",
        "def func1_node(state: GraphState) -> dict:\n",
        "  # Assuming 'x' and 'y' are part of the initial input to the graph\n",
        "  x = state.get(\"x\", 0)\n",
        "  y = state.get(\"y\", 0)\n",
        "  result = x + y\n",
        "  return {\"func1_output\": result}\n",
        "\n",
        "def func2_node(state: GraphState) -> dict:\n",
        "  input_for_func2 = state.get(\"func1_output\", 0)\n",
        "  result = 2 * input_for_func2\n",
        "  return {\"func2_output\": result}"
      ],
      "metadata": {
        "id": "mOs7pbh0vZdX"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "workflow = StateGraph(GraphState) # Pass the state schema here\n",
        "\n",
        "workflow.add_node(\"node_1\", func1_node)\n",
        "workflow.add_node(\"node_2\", func2_node)\n",
        "\n",
        "workflow.add_edge(\"node_1\", \"node_2\")\n",
        "\n",
        "workflow.set_entry_point(\"node_1\")\n",
        "workflow.set_finish_point(\"node_2\")\n",
        "\n",
        "app = workflow.compile()"
      ],
      "metadata": {
        "id": "6KKBQcwFvl8g"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app.invoke({\"x\": 10, \"y\":5})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kOeSMerwt7I",
        "outputId": "eebd2dfb-c264-43b8-dcfc-bf2517ce3a3b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': 10, 'y': 5, 'func1_output': 15, 'func2_output': 30}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(app.get_graph().draw_mermaid_png()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "YR83rcP5w0r6",
        "outputId": "e43943cb-15ed-4ad4-e83c-80a42f1f7742"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}